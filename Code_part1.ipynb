{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ea2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import lower\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ce8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/11 19:33:08 WARN Utils: Your hostname, MacBook-Air-Ekaterina-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.5 instead (on interface en0)\n",
      "23/09/11 19:33:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/11 19:33:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    " .builder\n",
    " .appName('project2_part1')\n",
    " .enableHiveSupport()\n",
    " .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe85b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>project2_part1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1525425e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8335ec7",
   "metadata": {},
   "source": [
    "# Ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb5d4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>athletics</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>swimming</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cycling</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gymnastics</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>rowing</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>skiing</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>curling</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>hockey</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>figure_skating</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>snowboarding</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id      Discipline  Season\n",
       "0       1       athletics  summer\n",
       "1       2        swimming  summer\n",
       "2       3         cycling  summer\n",
       "3       4      gymnastics  summer\n",
       "4       5          rowing  summer\n",
       "5       6          skiing  winter\n",
       "6       7         curling  winter\n",
       "7       8          hockey  winter\n",
       "8       9  figure_skating  winter\n",
       "9      10    snowboarding  winter"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([(1, \"athletics\", \"summer\"),\n",
    "        (2, \"swimming\", \"summer\"),\n",
    "        (3, \"cycling\", \"summer\"),\n",
    "        (4, \"gymnastics\", \"summer\"),\n",
    "        (5, \"rowing\", \"summer\"),\n",
    "        (6, \"skiing\", \"winter\"),\n",
    "        (7, \"curling\", \"winter\"),\n",
    "        (8, \"hockey\", \"winter\"),\n",
    "        (9, \"figure_skating\", \"winter\"),\n",
    "        (10, \"snowboarding\", \"winter\")])\n",
    "data.columns = ['row_id', 'Discipline', 'Season']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f82e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_data = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9f9345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+------+\n",
      "|row_id|    Discipline|Season|\n",
      "+------+--------------+------+\n",
      "|     1|     athletics|summer|\n",
      "|     2|      swimming|summer|\n",
      "|     3|       cycling|summer|\n",
      "|     4|    gymnastics|summer|\n",
      "|     5|        rowing|summer|\n",
      "|     6|        skiing|winter|\n",
      "|     7|       curling|winter|\n",
      "|     8|        hockey|winter|\n",
      "|     9|figure_skating|winter|\n",
      "|    10|  snowboarding|winter|\n",
      "+------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01784c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_data.coalesce(1).write.csv('olympic_disciplines.csv', header = True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351c7d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athletes.csv             README.md\r\n",
      "Code_part1.ipynb         \u001b[34molympic_disciplines.csv\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb5f1c",
   "metadata": {},
   "source": [
    "# Ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82adb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes = spark.read.csv('Athletes.csv', header = True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "270ed00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes = athletes.withColumn(\"Discipline\", lower(\"Discipline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4162a465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|                Name|                 NOC|         Discipline|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|     AALERUD Katrine|              Norway|       cycling road|\n",
      "|         ABAD Nestor|               Spain|artistic gymnastics|\n",
      "|   ABAGNALE Giovanni|               Italy|             rowing|\n",
      "|      ABALDE Alberto|               Spain|         basketball|\n",
      "|       ABALDE Tamara|               Spain|         basketball|\n",
      "|           ABALO Luc|              France|           handball|\n",
      "|        ABAROA Cesar|               Chile|             rowing|\n",
      "|       ABASS Abobakr|               Sudan|           swimming|\n",
      "|    ABBASALI Hamideh|Islamic Republic ...|             karate|\n",
      "|       ABBASOV Islam|          Azerbaijan|          wrestling|\n",
      "|        ABBINGH Lois|         Netherlands|           handball|\n",
      "|         ABBOT Emily|           Australia|rhythmic gymnastics|\n",
      "|       ABBOTT Monica|United States of ...|  baseball/softball|\n",
      "|ABDALLA Abubaker ...|               Qatar|          athletics|\n",
      "|      ABDALLA Maryam|               Egypt|  artistic swimming|\n",
      "|      ABDALLAH Shahd|               Egypt|  artistic swimming|\n",
      "| ABDALRASOOL Mohamed|               Sudan|               judo|\n",
      "|   ABDEL LATIF Radwa|               Egypt|           shooting|\n",
      "|    ABDEL RAZEK Samy|               Egypt|           shooting|\n",
      "|   ABDELAZIZ Abdalla|               Egypt|             karate|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce4a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|          Discipline|Total athletes|\n",
      "+--------------------+--------------+\n",
      "|              hockey|           406|\n",
      "|    beach volleyball|            90|\n",
      "|            shooting|           342|\n",
      "|        cycling road|           190|\n",
      "|      sport climbing|            37|\n",
      "|          water polo|           269|\n",
      "|   marathon swimming|            49|\n",
      "|          equestrian|           237|\n",
      "|      3x3 basketball|            62|\n",
      "|          basketball|           280|\n",
      "|             sailing|           336|\n",
      "|trampoline gymnas...|            31|\n",
      "|  cycling bmx racing|            43|\n",
      "|   artistic swimming|            98|\n",
      "|           triathlon|           106|\n",
      "|             archery|           122|\n",
      "|             surfing|            38|\n",
      "|        table tennis|           164|\n",
      "|           wrestling|           279|\n",
      "|        canoe sprint|           236|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 =athletes.groupBy(\"Discipline\").count().withColumnRenamed(\"count\",\"Total athletes\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e38ee34e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/Users/ekaterinaprokopeva/DE_Project_Part_2/total_athletes.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_athletes.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/pyspark/sql/readwriter.py:1656\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1656\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/Users/ekaterinaprokopeva/DE_Project_Part_2/total_athletes.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df2.write.parquet('total_athletes.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74c97c",
   "metadata": {},
   "source": [
    "# Ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c1f04",
   "metadata": {},
   "source": [
    "3. Прочитайте исходный файл \"Athletes.csv\".\n",
    "Посчитайте в разрезе дисциплин сколько всего спортсменов в каждой из дисциплин принимало участие.\n",
    "Получившийся результат нужно объединить с сгенерированным вами DataFrame из 1-го задания и в итоге вывести количество участников, только по тем дисциплинам, что есть в вашем сгенерированном DataFrame.\n",
    "Результат сохраните в формате parquet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d69e993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|                Name|                 NOC|         Discipline|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|     AALERUD Katrine|              Norway|       cycling road|\n",
      "|         ABAD Nestor|               Spain|artistic gymnastics|\n",
      "|   ABAGNALE Giovanni|               Italy|             rowing|\n",
      "|      ABALDE Alberto|               Spain|         basketball|\n",
      "|       ABALDE Tamara|               Spain|         basketball|\n",
      "|           ABALO Luc|              France|           handball|\n",
      "|        ABAROA Cesar|               Chile|             rowing|\n",
      "|       ABASS Abobakr|               Sudan|           swimming|\n",
      "|    ABBASALI Hamideh|Islamic Republic ...|             karate|\n",
      "|       ABBASOV Islam|          Azerbaijan|          wrestling|\n",
      "|        ABBINGH Lois|         Netherlands|           handball|\n",
      "|         ABBOT Emily|           Australia|rhythmic gymnastics|\n",
      "|       ABBOTT Monica|United States of ...|  baseball/softball|\n",
      "|ABDALLA Abubaker ...|               Qatar|          athletics|\n",
      "|      ABDALLA Maryam|               Egypt|  artistic swimming|\n",
      "|      ABDALLAH Shahd|               Egypt|  artistic swimming|\n",
      "| ABDALRASOOL Mohamed|               Sudan|               judo|\n",
      "|   ABDEL LATIF Radwa|               Egypt|           shooting|\n",
      "|    ABDEL RAZEK Samy|               Egypt|           shooting|\n",
      "|   ABDELAZIZ Abdalla|               Egypt|             karate|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bff3122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = athletes.join(spark_data, 'Discipline', 'inner').groupBy('Discipline').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f8c64d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Discipline|count|\n",
      "+----------+-----+\n",
      "| athletics| 2068|\n",
      "|  swimming|  743|\n",
      "|    rowing|  496|\n",
      "|    hockey|  406|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47c914f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.write.parquet('filtered_athletes.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
