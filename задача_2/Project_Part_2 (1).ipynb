{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install delta-spark==1.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w81PMnbVS8B",
        "outputId": "57fb579e-1b63-471a-859c-3b7ebaee28ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting delta-spark==1.2.0\n",
            "  Downloading delta_spark-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting pyspark<3.3.0,>=3.2.0 (from delta-spark==1.2.0)\n",
            "  Downloading pyspark-3.2.4.tar.gz (281.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from delta-spark==1.2.0) (6.8.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.0.0->delta-spark==1.2.0) (3.16.2)\n",
            "Collecting py4j==0.10.9.5 (from pyspark<3.3.0,>=3.2.0->delta-spark==1.2.0)\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.4-py2.py3-none-any.whl size=282040915 sha256=150074e26b7b6ded19c229076ef2fde8730917dfe4b114b3c53f517480c4c772\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/e3/c8/c358dac750f2b6a4b03328d10e05a5c69501664bd6504b6c3e\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark, delta-spark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed delta-spark-1.2.0 py4j-0.10.9.5 pyspark-3.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from datetime import datetime as dt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "P7BLhDHM4uHo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from delta import *\n",
        "\n",
        "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
      ],
      "metadata": {
        "id": "gQ516oLnWaxo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для поиска последней сессии\n",
        "def get_last_session_id(path_to_log_file):\n",
        "    logs_dataframe = pd.read_csv(path_to_log_file)\n",
        "    return str(logs_dataframe.iloc[-1]['Session ID'])"
      ],
      "metadata": {
        "id": "SgfDRnjOL4ni"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для записи информации о обработанной дельте в CSV-файл с заголовками\n",
        "def log_processed_delta(session_id, table_name, time, status):\n",
        "    # Путь к CSV-файлу\n",
        "    log_file_path = 'logs.csv'\n",
        "\n",
        "    # Проверяем существование файла\n",
        "    file_exists = os.path.exists(log_file_path)\n",
        "\n",
        "    # Записываем данные в CSV-файл\n",
        "    with open(log_file_path, 'a', newline='') as csvfile:\n",
        "        fieldnames = ['Session ID', 'Table Name', 'Time', 'Status']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        # Если файл не существует, записываем заголовки\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "\n",
        "        writer.writerow({'Session ID': session_id, 'Table Name': table_name, 'Time': time, 'Status': status})\n",
        "\n",
        "\n",
        "# log_processed_delta(session_id, table_name, time, status)"
      ],
      "metadata": {
        "id": "w4tL3u_dEabt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "PH0SKOQ22gSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configure\n",
        "delta_path = '/content/drive/MyDrive/data_deltas'  # Путь к директории с дельтами\n",
        "filepath = '/content/drive/MyDrive/data_deltas/1000/md_account_d.csv'\n",
        "table_name = 'md_account_d'\n",
        "pk_column_name = 'ACCOUNT_RK'"
      ],
      "metadata": {
        "id": "x9lf2Xis2f4H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = spark.read.csv(filepath, header = True, sep = ';', inferSchema = True)\n",
        "temp.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xk-I9fF3GZd",
        "outputId": "b6a6ea50-d47e-4ba1-aed6-a7136db0b856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- DATA_ACTUAL_DATE: string (nullable = true)\n",
            " |-- DATA_ACTUAL_END_DATE: string (nullable = true)\n",
            " |-- ACCOUNT_RK: integer (nullable = true)\n",
            " |-- ACCOUNT_NUMBER: decimal(20,0) (nullable = true)\n",
            " |-- CHAR_TYPE: string (nullable = true)\n",
            " |-- CURRENCY_RK: integer (nullable = true)\n",
            " |-- CURRENCY_CODE: integer (nullable = true)\n",
            " |-- CLIENT_ID: integer (nullable = true)\n",
            " |-- BRANCH_ID: integer (nullable = true)\n",
            " |-- OPEN_IN_INTERNET: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Создаем датафрейм для зеркала (пока что его не существует)\n",
        "mirror = spark.createDataFrame([], schema=temp.schema)"
      ],
      "metadata": {
        "id": "Q_-7X7zK3KEI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mirror.write.format(\"delta\").mode(\"overwrite\").save(\"/content/temp\")"
      ],
      "metadata": {
        "id": "Nx2XFGNral5k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delta_mirror = DeltaTable.forPath(spark, \"/content/temp\")"
      ],
      "metadata": {
        "id": "SvtFr1d74op4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delta_mirror.toDF().show()"
      ],
      "metadata": {
        "id": "rd-XfAZ_4osO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714a920b-0e5e-435f-8573-cc1219074f42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+----------+--------------+---------+-----------+-------------+---------+---------+----------------+\n",
            "|DATA_ACTUAL_DATE|DATA_ACTUAL_END_DATE|ACCOUNT_RK|ACCOUNT_NUMBER|CHAR_TYPE|CURRENCY_RK|CURRENCY_CODE|CLIENT_ID|BRANCH_ID|OPEN_IN_INTERNET|\n",
            "+----------------+--------------------+----------+--------------+---------+-----------+-------------+---------+---------+----------------+\n",
            "+----------------+--------------------+----------+--------------+---------+-----------+-------------+---------+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing"
      ],
      "metadata": {
        "id": "bCI-4jeY4pa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_delta(delta_path, table_name, pk_column_name):\n",
        "\n",
        "    # Получаем список директорий (без скрытых)\n",
        "    delta_dirs = [d for d in os.listdir(delta_path) if not d.startswith('.')]\n",
        "\n",
        "    # Фильтруем список дельт, оставляя только непрошедшие\n",
        "    if os.path.exists('logs.csv'):\n",
        "        last_id = get_last_session_id('logs.csv')\n",
        "        delta_dirs = [delta_id for delta_id in delta_dirs if delta_id > last_id]\n",
        "\n",
        "\n",
        "    for delta_id in delta_dirs:\n",
        "\n",
        "        #переход к файлу\n",
        "        delta_dir = os.path.join(delta_path, delta_id)\n",
        "        filename = os.listdir(delta_dir)[0]\n",
        "        deltafilepath = os.path.join(delta_dir, filename)\n",
        "\n",
        "        temp = spark.read.csv(deltafilepath, header = True, sep = ';', inferSchema = True)\n",
        "\n",
        "        log_processed_delta(delta_id, table_name, dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"),'START')\n",
        "\n",
        "        delta_mirror.alias(\"mirror\").merge(\n",
        "        source = temp.alias(\"updates\"),\n",
        "        condition = f\"mirror.{pk_column_name} = updates.{pk_column_name}\"\n",
        "    ).whenMatchedUpdate(set =\n",
        "        {\n",
        "        \"DATA_ACTUAL_DATE\": \"updates.DATA_ACTUAL_DATE\",\n",
        "        \"DATA_ACTUAL_END_DATE\": \"updates.DATA_ACTUAL_END_DATE\",\n",
        "        \"ACCOUNT_NUMBER\": \"updates.ACCOUNT_NUMBER\",\n",
        "        \"CHAR_TYPE\": \"updates.CHAR_TYPE\",\n",
        "        \"CURRENCY_RK\": \"updates.CURRENCY_RK\",\n",
        "        \"CURRENCY_CODE\": \"updates.CURRENCY_CODE\",\n",
        "        \"CLIENT_ID\": \"updates.CLIENT_ID\",\n",
        "        \"BRANCH_ID\": \"updates.BRANCH_ID\",\n",
        "        \"OPEN_IN_INTERNET\": \"updates.OPEN_IN_INTERNET\",\n",
        "        }\n",
        "    ).whenNotMatchedInsert(values =\n",
        "        {\n",
        "        \"DATA_ACTUAL_DATE\": \"updates.DATA_ACTUAL_DATE\",\n",
        "        \"DATA_ACTUAL_END_DATE\": \"updates.DATA_ACTUAL_END_DATE\",\n",
        "        \"ACCOUNT_RK\": \"updates.ACCOUNT_RK\",\n",
        "        \"ACCOUNT_NUMBER\": \"updates.ACCOUNT_NUMBER\",\n",
        "        \"CHAR_TYPE\": \"updates.CHAR_TYPE\",\n",
        "        \"CURRENCY_RK\": \"updates.CURRENCY_RK\",\n",
        "        \"CURRENCY_CODE\": \"updates.CURRENCY_CODE\",\n",
        "        \"CLIENT_ID\": \"updates.CLIENT_ID\",\n",
        "        \"BRANCH_ID\": \"updates.BRANCH_ID\",\n",
        "        \"OPEN_IN_INTERNET\": \"updates.OPEN_IN_INTERNET\",\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "        log_processed_delta(delta_id, table_name, dt.now().strftime(\"%Y-%m-%d %H:%M:%S\"),'END')\n",
        "        delta_mirror.toDF().show()"
      ],
      "metadata": {
        "id": "9vdV3dCOPBB2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# delta_path = '/content/drive/MyDrive/data_deltas'  # Путь к директории с дельтами\n",
        "# table_name = 'md_account_d'\n",
        "# pk_column_name = 'ACCOUNT_RK'\n",
        "\n",
        "process_delta(delta_path, table_name, pk_column_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtyScZV6LDO0",
        "outputId": "00d0f563-4b0a-4a6a-adf9-05db5fd44932"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+----------+--------------------+---------+-----------+-------------+---------+---------+----------------+\n",
            "|DATA_ACTUAL_DATE|DATA_ACTUAL_END_DATE|ACCOUNT_RK|      ACCOUNT_NUMBER|CHAR_TYPE|CURRENCY_RK|CURRENCY_CODE|CLIENT_ID|BRANCH_ID|OPEN_IN_INTERNET|\n",
            "+----------------+--------------------+----------+--------------------+---------+-----------+-------------+---------+---------+----------------+\n",
            "|      15.02.2018|          31.12.2050|     13560|30110810300000008001|        A|         34|          643|       20|      105|               Y|\n",
            "|      21.04.2018|          31.12.2050|     13630|30102810900000002185|        A|         34|          643|       21|      107|            null|\n",
            "|      21.04.2018|          31.12.2050|     13811|30221978100000008100|        A|         44|          978|       33|      201|            null|\n",
            "|      21.04.2018|          31.12.2050|     13871|30222978200000004100|        P|         44|          978|       63|      105|               Y|\n",
            "|      01.01.2018|          31.12.2050|     13904|30204810500000002001|        A|         34|          643|       37|      201|               Y|\n",
            "|      21.04.2018|          31.12.2050|     13905|30202810900000002001|        A|         34|          643|       12|      107|            null|\n",
            "|      01.01.2018|          31.12.2050|     13906|30114756800000051003|        A|         30|          756|       40|      105|            null|\n",
            "|      15.02.2018|          31.12.2050|     14136|30220826800838890001|        P|         31|          826|       57|      107|            null|\n",
            "|      01.01.2018|          31.12.2050|     14138|30220978800838890001|        P|         44|          978|       24|      105|               Y|\n",
            "|      01.01.2018|          31.12.2050|     17132|30111810000000666001|        P|         34|          643|       19|      101|            null|\n",
            "|      15.02.2018|          31.12.2050|     17244|30111810900000672001|        P|         34|          643|       99|      127|            null|\n",
            "|      01.01.2018|          31.12.2050|     17434|30111810900000051004|        P|         34|          643|        9|      101|            null|\n",
            "|      10.03.2018|          31.12.2050|     17439|30111810500000438001|        P|         34|          643|        4|      203|            null|\n",
            "|      10.03.2018|          31.12.2050|     17442|30111810800000565001|        P|         34|          810|       82|      107|               N|\n",
            "|      10.03.2018|          31.12.2050|     18006|30233978800450003001|        A|         44|          978|       71|      201|            null|\n",
            "|      10.03.2018|          31.12.2050|     18164|30232810000450001001|        P|         34|          810|       90|      103|            null|\n",
            "|      21.04.2018|          31.12.2050|     18165|30232978900450001001|        P|         44|          978|       26|      120|               Y|\n",
            "|      01.01.2018|          31.12.2050|     24656|30114840700000770002|        A|         35|          840|        2|      107|            null|\n",
            "|      15.02.2018|          31.12.2050|     24753|30114124400000004011|        A|         42|          124|       97|      101|            null|\n",
            "|      21.04.2018|          31.12.2050|     25068|30222810400000001100|        P|         34|          643|       74|      115|               Y|\n",
            "+----------------+--------------------+----------+--------------------+---------+-----------+-------------+---------+---------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Запись в итоговый файл"
      ],
      "metadata": {
        "id": "4FqSVJoTWvI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_mirror.toDF().write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save('/content/mirr_md_account_d')"
      ],
      "metadata": {
        "id": "Fcn5DigiTY_4"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}